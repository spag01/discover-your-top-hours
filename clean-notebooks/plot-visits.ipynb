{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from custom_process_domain import process_domain_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from zoneinfo import ZoneInfo\n",
    "import seaborn\n",
    "seaborn.set()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_USERS = { # Just to make sure we're good\n",
    "  \"Juan\": \"Juan\",\n",
    "  \"Nathan\": \"Nathan\",\n",
    "  \"Sanyam\": \"Sanyam\",\n",
    "  \"Nipun\": \"Nipun\",\n",
    "  \"Parsa\": \"Parsa\",\n",
    "}\n",
    "\n",
    "# User Input\n",
    "USER = POSSIBLE_USERS[\"Sanyam\"] # Change this line to one of the names above\n",
    "\n",
    "# START_DATE\n",
    "START_DATE_YEAR = 2022\n",
    "START_DATE_MONTH = 9\n",
    "START_DATE_DAY = 19\n",
    "\n",
    "WEEKS_TO_INCREMENT = 0 # Add WEEKS_TO_INCREMENT * 7 days to START_TIME\n",
    "DATE_INTERVAL_TYPE = 'month' # 'weekend', 'week', 'all_week', 'all_time\n",
    "\n",
    "##############################\n",
    "# Graphs\n",
    "##############################\n",
    "\n",
    "# Save Graphs\n",
    "SAVE_GRAPH_1 = False\n",
    "SAVE_GRAPH_2 = False\n",
    "SAVE_GRAPH_3 = False\n",
    "SAVE_GRAPH_4 = False\n",
    "SAVE_GRAPH_5 = True\n",
    "SAVE_GRAPH_6 = True\n",
    "\n",
    "##############################\n",
    "# Options\n",
    "##############################\n",
    "MIN_CHROME_VISIT_DURATION = 5\n",
    "MAX_CHROME_VISIT_DURATION = 2.88e+10 # 8 hours in microseconds\n",
    "\n",
    "MIN_SAFARI_SCORE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USER == \"Nathan\":\n",
    "  DB_FILE = \"../data/history--2022-10-21--Nathan-Tsai.sqlite3\"\n",
    "  RATING_FILE = \"../rated-output/Ratings - CMPT 353 - Nathan Tsai (1).csv\"\n",
    "  USER_TIMEZONE_STRING = 'US/Pacific'\n",
    "elif USER == \"Juan\":\n",
    "  DB_FILE = \"../data/history--2022-10-21--Juan-Gonzalez.sqlite3\"\n",
    "  RATING_FILE = \"../rated-output/Ratings - CMPT 353 - Juan Gonzalez.csv\"\n",
    "  USER_TIMEZONE_STRING = 'US/Pacific'\n",
    "elif USER == \"Sanyam\":\n",
    "  DB_FILE = \"../data/history--2022-11-25--Sanyam-Safari.db\"\n",
    "  RATING_FILE = \"../rated-output/Ratings of Inputted Users - CMPT 353 - Sanyam (2).csv\"\n",
    "  USER_TIMEZONE_STRING = 'US/Pacific'\n",
    "elif USER == \"Nipun\":\n",
    "  DB_FILE = \"../data/history--2022-11-26--Nipun-Safari.db\"\n",
    "  RATING_FILE = \"../rated-output/Ratings of Inputted Users - CMPT 353 - Nipun.csv\"\n",
    "  USER_TIMEZONE_STRING = 'Asia/Colombo' # India standard time: UTC+5:30\n",
    "elif USER == \"Parsa\":\n",
    "  DB_FILE = \"../data/history--2022-12-05--Pasha.sqlite3\"\n",
    "  RATING_FILE = \"../rated-output/Ratings of Inputted Users - CMPT 353 - Pasha.csv\"\n",
    "  USER_TIMEZONE_STRING = 'Asia/Colombo' # India standard time: UTC+5:30\n",
    "else:\n",
    "  assert(False and \"User name is invalid\")\n",
    "\n",
    "USER_TIMEZONE = ZoneInfo(USER_TIMEZONE_STRING)\n",
    "TIMEZONE_STRING = USER_TIMEZONE_STRING\n",
    "\n",
    "\n",
    "START_TIME = datetime(\n",
    "  START_DATE_YEAR,\n",
    "  START_DATE_MONTH,\n",
    "  START_DATE_DAY, \n",
    "  tzinfo=USER_TIMEZONE\n",
    ") # the data to look at. Should be a Monday\n",
    "\n",
    "# The values per user productivity\n",
    "productivity_to_int_map = {\n",
    "  'Always Distracted' : -2,\n",
    "  'Mostly Distracted' : -1,\n",
    "  'Neutrel' : 0,\n",
    "  'Mostly Intentional' : 1,\n",
    "  'Always Intentional' : 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format User Input for Graphs / Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increment by a number of weeks\n",
    "START_TIME = START_TIME + timedelta(days=7 * WEEKS_TO_INCREMENT)\n",
    "\n",
    "# Add 1 day if weekend, otherwise use weekday\n",
    "date_types = {\n",
    "  'weekend': 1,\n",
    "  'week': 4,\n",
    "  'all_week': 6,\n",
    "  'month': 30,\n",
    "  'all_time': 7 * 52 * 3, # 3 years\n",
    "}\n",
    "DAYS_TO_ADD = date_types[DATE_INTERVAL_TYPE]\n",
    "\n",
    "if DATE_INTERVAL_TYPE == 'weekend':\n",
    "  START_TIME = START_TIME + timedelta(days=-2)\n",
    "\n",
    "END_TIME = START_TIME + timedelta(days=DAYS_TO_ADD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATE_INTERVAL_TYPE == 'all_time':\n",
    "  start_date_for_graph = START_TIME.strftime('%a, %b %d %Y')\n",
    "else:\n",
    "  start_date_for_graph = START_TIME.strftime('%a, %b %d')\n",
    "\n",
    "  \n",
    "end_date_for_graph = END_TIME.strftime('%a, %b %d, %Y')\n",
    "time_for_graph = \"{} - {}\".format(start_date_for_graph, end_date_for_graph)\n",
    "CUSTOM_PARAMS_FOR_GRAPH = \"{}: {}\".format(USER, time_for_graph)\n",
    "\n",
    "start_date_for_file = START_TIME.strftime('%b-%d-%Y')\n",
    "end_date_for_file = END_TIME.strftime('%b-%d-%Y')\n",
    "time_for_file = \"{}--{}\".format(start_date_for_file, end_date_for_file)\n",
    "CUSTOM_PARAMS_FOR_FILE = \"{}--{}\".format(USER, time_for_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "WINDOWS_EPOCH_MICROSECS      = -11644473600000 * 1000\n",
    "SAFARI_TIME_UPDATE           = 978307200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the type of Database\n",
    "TYPE_IS_SAFARI = \"TYPE_IS_SAFARI\"\n",
    "TYPE_IS_CHROME = \"TYPE_IS_CHROME\"\n",
    "TYPE_OF_DB = {\n",
    "  \"db\": TYPE_IS_SAFARI,\n",
    "  \"sqlite\": TYPE_IS_CHROME,\n",
    "  \"sqlite3\": TYPE_IS_CHROME,\n",
    "}\n",
    "\n",
    "extension = DB_FILE.split(\".\")[-1]\n",
    "DB_TYPE = TYPE_OF_DB[extension]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_INCREMENTS = 24 * 2\n",
    "DAY_IN_SECONDS = 60 * 60 * 24\n",
    "ROUND_TO = DAY_IN_SECONDS / NUMBER_OF_INCREMENTS\n",
    "\n",
    "def get_half_hour(data: pd.Series) -> pd.Series:\n",
    "  return (data / ROUND_TO).round().astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bunch of Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load History Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DB_TYPE == TYPE_IS_CHROME:\n",
    "  query_get_urls_and_times = \"\"\"\n",
    "  SELECT v.id, v.visit_time, v.visit_duration, u.url\n",
    "  FROM 'visits' as v \n",
    "  LEFT JOIN urls u ON u.id = v.url\n",
    "  \"\"\"\n",
    "\n",
    "  TIME_CORRECTION_TO_ADD_TO_VISIT_TIME = WINDOWS_EPOCH_MICROSECS\n",
    "elif DB_TYPE == TYPE_IS_SAFARI:\n",
    "  query_get_urls_and_times = \"\"\"\n",
    "  SELECT v.id, v.visit_time, v.score, u.url\n",
    "  FROM 'history_visits' as v \n",
    "  LEFT JOIN history_items u ON u.id = v.history_item\n",
    "  \"\"\"\n",
    "  TIME_CORRECTION_TO_ADD_TO_VISIT_TIME = SAFARI_TIME_UPDATE\n",
    "else:\n",
    "  assert(False and \"Extension of database is invalid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(DB_FILE) as con:\n",
    "  visits = pd.read_sql_query(query_get_urls_and_times, con)\n",
    "\n",
    "visits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit time in microseconds (s/1,000,000)\n",
    "# https://chromium.googlesource.com/chromium/src/+/lkgr/base/time/time.h\n",
    "\n",
    "if DB_TYPE == TYPE_IS_CHROME:\n",
    "  visit_time_in_ns = (visits['visit_time'] + TIME_CORRECTION_TO_ADD_TO_VISIT_TIME) * 1000\n",
    "  visits['visit_time_epoch'] = pd.to_datetime(visit_time_in_ns, unit='ns', utc=True).map(lambda x: x.tz_convert(TIMEZONE_STRING))\n",
    "elif DB_TYPE == TYPE_IS_SAFARI:\n",
    "  visit_time_in_ns = (visits['visit_time'] + TIME_CORRECTION_TO_ADD_TO_VISIT_TIME)\n",
    "  visits['visit_time_epoch'] = pd.to_datetime(visit_time_in_ns, unit='s', utc=True).map(lambda x: x.tz_convert(TIMEZONE_STRING))\n",
    "else:\n",
    "  assert(False and \"Extension of database is invalid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits['domain'] = visits['url'].apply(process_domain_normal)\n",
    "\n",
    "visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits.tail(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(RATING_FILE, index_col='domain')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the Data based on Time + Visit Duration/Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greaterthanStartTime = visits['visit_time_epoch'] >= START_TIME\n",
    "lessThanEndTime = visits['visit_time_epoch'] <= END_TIME\n",
    "visits_this_semester = visits[greaterthanStartTime & lessThanEndTime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'visit_duration' in visits_this_semester.columns:\n",
    "  min_visit_option = visits_this_semester[visits_this_semester['visit_duration'] >= MIN_CHROME_VISIT_DURATION]\n",
    "  min_visit_option = min_visit_option[min_visit_option['visit_duration'] < MAX_CHROME_VISIT_DURATION]\n",
    "elif 'score' in visits_this_semester.columns:\n",
    "  min_visit_option = visits_this_semester[visits_this_semester['score'] >= MIN_SAFARI_SCORE]\n",
    "else:\n",
    "  min_visit_option = visits_this_semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_data = min_visit_option.join(ratings[['manual_rating']], on=\"domain\", how='left')\n",
    "final_data['productivity_scale'] = final_data['manual_rating'].map(productivity_to_int_map)\n",
    "final_data['time_of_day'] = final_data['visit_time_epoch'].dt.hour * 60 * 60 + final_data['visit_time_epoch'].dt.minute * 60 + final_data['visit_time_epoch'].dt.second\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill empty productivity scores with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove N/A\n",
    "refined_data = final_data.copy()\n",
    "refined_data['productivity_scale'] = refined_data['productivity_scale'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 1: Productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(refined_data['time_of_day'], refined_data['productivity_scale'], 'r.', alpha=0.05)\n",
    "plt.xticks(np.arange(0, 60 * 60 * 24, step=60 * 60), np.arange(0, 24, step=1)) # Hours\n",
    "plt.title(\"Productivity Level over Time \\n {}\".format(CUSTOM_PARAMS_FOR_GRAPH))\n",
    "plt.xlabel(\"Time (Hour)\")\n",
    "plt.ylabel(\"Productivity level\")\n",
    "# plt.xticks(np.arange(0, 60 * 60 * 24, step=60 * 30), np.arange(0, 24, step=0.5))\n",
    "\n",
    "if SAVE_GRAPH_1:\n",
    "  plt.savefig(\"../plots/XX-filtered-data--a-week-of-data--{}.png\".format(CUSTOM_PARAMS_FOR_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work for Graph 2: Distracted Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_distracted = refined_data[refined_data['productivity_scale'] < 0.5].copy()\n",
    "only_distracted['half_hour'] = get_half_hour(only_distracted['time_of_day'])\n",
    "\n",
    "only_distracted_agg = only_distracted.groupby('half_hour').agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(only_distracted_agg['half_hour'], only_distracted_agg['productivity_scale'], 'r-')\n",
    "plt.plot(only_distracted_agg['half_hour'], only_distracted_agg['productivity_scale'], 'r.')\n",
    "plt.xticks(np.arange(0, 48, 2), np.arange(0, 24, step=1)) # Half Hours\n",
    "plt.title(\"Distracted Level throughout the day: \\n ({})\".format(CUSTOM_PARAMS_FOR_GRAPH))\n",
    "plt.xlabel(\"Time (Hour)\")\n",
    "plt.ylabel(\"Sum of Productivity Level (-1 for Distracted. -2 for Very Distracted)\")\n",
    "\n",
    "if SAVE_GRAPH_2:\n",
    "  plt.savefig(\"../plots/XX-filtered-data--a-week-of-data--{}.png\".format(CUSTOM_PARAMS_FOR_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph 3: Account for the visit duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (for Chrome only browsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DB_TYPE == TYPE_IS_CHROME:\n",
    "  adj_prod_pre = refined_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DB_TYPE == TYPE_IS_CHROME:\n",
    "  # adj_prod = adj_prod_pre\n",
    "  NUMBER_OF_INCREMENTS = 24 * (60 / 30) # 2 => half hour\n",
    "  DAY_IN_SECONDS = 60 * 60 * 24\n",
    "  ROUND_TO = DAY_IN_SECONDS / NUMBER_OF_INCREMENTS\n",
    "\n",
    "  adj_prod_pre['adjusted_time'] = adj_prod_pre[['visit_duration', 'visit_time_epoch']].apply(\n",
    "    lambda x: np.arange(0, x['visit_duration'] // 1e6, ROUND_TO) + x['visit_time_epoch'].value // 1e9, axis=1)\n",
    "\n",
    "  adj_prod = adj_prod_pre.explode('adjusted_time')\n",
    "  adj_prod.dropna(subset=['adjusted_time'], inplace=True)\n",
    "else:\n",
    "  adj_prod = refined_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DB_TYPE == TYPE_IS_CHROME:\n",
    "  adj_prod['adjusted_datetime'] = pd.to_datetime(adj_prod['adjusted_time'], unit='s', utc=True).map(lambda x: x.tz_convert(TIMEZONE_STRING))\n",
    "\n",
    "  adj_prod['time_of_day'] = adj_prod['adjusted_datetime'].dt.hour * 60 * 60 \\\n",
    "    + adj_prod['adjusted_datetime'].dt.minute * 60 \\\n",
    "    + adj_prod['adjusted_datetime'].dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_prod['half_hour'] = get_half_hour(adj_prod['time_of_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 3.1: Only Distracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_prod_distracted = adj_prod[adj_prod['productivity_scale'] < 0.5]\n",
    "\n",
    "adj_prod_distracted_agg = adj_prod_distracted.groupby('half_hour').agg('sum').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_IS_CHROME:\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plt.plot(adj_prod_distracted_agg['half_hour'], adj_prod_distracted_agg['productivity_scale'], 'r-')\n",
    "  plt.plot(adj_prod_distracted_agg['half_hour'], adj_prod_distracted_agg['productivity_scale'], 'r.')\n",
    "  plt.xticks(np.arange(0, NUMBER_OF_INCREMENTS, NUMBER_OF_INCREMENTS/24), np.arange(0, 24, step=1)) # Half Hours\n",
    "  plt.title(\"Adjusted Productivity while Accouting for Visit Duration: \\n ({})\".format(CUSTOM_PARAMS_FOR_GRAPH))\n",
    "  plt.xlabel(\"Time (Hour)\")\n",
    "  plt.ylabel(\"Sum of Productivity Level (-1 for Distracted. -2 for Very Distracted)\")\n",
    "\n",
    "  if SAVE_GRAPH_3:\n",
    "    plt.savefig(\"../plots/XX-filtered-data--a-week-of-data--{}.png\".format(CUSTOM_PARAMS_FOR_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 3.2: With Productive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_prod['adjusted_prod'] = adj_prod['productivity_scale']\n",
    "positive_sum = adj_prod[adj_prod['productivity_scale'] > 0]['productivity_scale'].sum()\n",
    "adj_prod.loc[adj_prod['productivity_scale'] > 0, 'adjusted_prod'] /= positive_sum\n",
    "\n",
    "negative_count = adj_prod[adj_prod['productivity_scale'] < 0]['productivity_scale'].sum()\n",
    "adj_prod.loc[adj_prod['productivity_scale'] < 0, 'adjusted_prod'] /= -negative_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_prod_agg = adj_prod.groupby('half_hour').agg('sum').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(adj_prod_agg['half_hour'], adj_prod_agg['adjusted_prod'], 'r-')\n",
    "plt.plot(adj_prod_agg['half_hour'], adj_prod_agg['adjusted_prod'], 'r.')\n",
    "plt.axhline(y=0, color='b', linestyle='--', alpha=0.5)\n",
    "plt.xticks(np.arange(0, NUMBER_OF_INCREMENTS, NUMBER_OF_INCREMENTS/24), np.arange(0, 24, step=1)) # Half Hours\n",
    "plt.title(\"Adjusted Productivity while Accouting for Visit Duration: \\n ({})\".format(CUSTOM_PARAMS_FOR_GRAPH))\n",
    "plt.xlabel(\"Time (Hour)\")\n",
    "plt.ylabel(\"Sum of Adjusted Productivity Level\")\n",
    "\n",
    "if SAVE_GRAPH_4:\n",
    "  plt.savefig(\"../plots/XX-filtered-data--a-week-of-data--{}.png\".format(CUSTOM_PARAMS_FOR_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph 4: Final, using Seaborn confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resetted_index = adj_prod.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 4.1: View separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productive_data_agg = resetted_index[resetted_index['productivity_scale'] >= 0]\n",
    "# \\\n",
    "#   .groupby('half_hour').agg('sum').reset_index()\n",
    "  \n",
    "unproductive_data_agg = resetted_index[resetted_index['productivity_scale'] <= 0]\n",
    "# \\\n",
    "  # .groupby('half_hour').agg('sum').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "seaborn.lineplot(\n",
    "    x='half_hour',\n",
    "    y='adjusted_prod',\n",
    "    data=productive_data_agg,\n",
    "    color='green',\n",
    "    marker='.',\n",
    ")\n",
    "seaborn.lineplot(\n",
    "    x='half_hour',\n",
    "    y='adjusted_prod',\n",
    "    data=unproductive_data_agg,\n",
    "    color='orange',\n",
    "    marker='.',\n",
    ")\n",
    "# plt.plot(productive_data_agg['half_hour'], productive_data_agg['adjusted_prod'], 'g-')\n",
    "# plt.plot(productive_data_agg['half_hour'], productive_data_agg['adjusted_prod'], 'g.')\n",
    "# plt.plot(unproductive_data_agg['half_hour'], unproductive_data_agg['adjusted_prod'], 'y-')\n",
    "# plt.plot(unproductive_data_agg['half_hour'], unproductive_data_agg['adjusted_prod'], 'y.')\n",
    "plt.axhline(y=0, color='b', linestyle='--', alpha=0.5)\n",
    "plt.xticks(np.arange(0, NUMBER_OF_INCREMENTS, NUMBER_OF_INCREMENTS/48), np.arange(0, 48, step=1)//2) # Half Hours\n",
    "\n",
    "ax = plt.gca()\n",
    "for x in ax.xaxis.get_ticklabels()[1::2]:\n",
    "  x.set_visible(False)\n",
    "\n",
    "plt.title(\"Normalized Productivity (NOT Accounting for Visit Duration): \\n ({})\".format(CUSTOM_PARAMS_FOR_GRAPH))\n",
    "plt.xlabel(\"Time (Hour)\")\n",
    "plt.ylabel(\"Mean + 95 confidence interval of Normalized Productivity\")\n",
    "\n",
    "if SAVE_GRAPH_5:\n",
    "  plt.savefig(\"../plots/XX-final-results--confidence-95-separate--{}--small\".format(CUSTOM_PARAMS_FOR_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_prod['adjusted_prod'] = adj_prod['productivity_scale']\n",
    "positive_sum = adj_prod[adj_prod['productivity_scale'] > 0]['productivity_scale'].sum()\n",
    "adj_prod.loc[adj_prod['productivity_scale'] > 0, 'adjusted_prod'] /= positive_sum\n",
    "\n",
    "negative_count = adj_prod[adj_prod['productivity_scale'] < 0]['productivity_scale'].sum()\n",
    "adj_prod.loc[adj_prod['productivity_scale'] < 0, 'adjusted_prod'] /= -negative_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 View Both Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_INCREMENTS_AT = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off_data = resetted_index[resetted_index['half_hour'] >= START_INCREMENTS_AT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "seaborn.lineplot(\n",
    "    x='half_hour',\n",
    "    y='adjusted_prod',\n",
    "    data=cut_off_data,\n",
    "    color='red',\n",
    "    marker='.',\n",
    ")\n",
    "plt.axhline(y=0, color='b', linestyle='--', alpha=0.5)\n",
    "plt.xticks(np.arange(START_INCREMENTS_AT, NUMBER_OF_INCREMENTS, (NUMBER_OF_INCREMENTS - START_INCREMENTS_AT)/(48 - START_INCREMENTS_AT)), np.arange(START_INCREMENTS_AT, 48, step=1)//2) # Half Hours\n",
    "# plt.xticks(np.arange(0, NUMBER_OF_INCREMENTS, NUMBER_OF_INCREMENTS/48), np.arange(0, 48, step=1)//2) # Half Hours\n",
    "\n",
    "ax = plt.gca()\n",
    "for x in ax.xaxis.get_ticklabels()[1::2]:\n",
    "  x.set_visible(False)\n",
    "\n",
    "plt.title(\"Normalized Productivity (NOT Accounting for Visit Duration): \\n ({})\".format(CUSTOM_PARAMS_FOR_GRAPH))\n",
    "plt.xlabel(\"Time (Hour)\")\n",
    "plt.ylabel(\"Mean + 95 confidence interval of Normalized Productivity\")\n",
    "\n",
    "if SAVE_GRAPH_6:\n",
    "    plt.savefig(\"../plots/XX-filtered-data--a-week-of-data--{}.png\".format(CUSTOM_PARAMS_FOR_FILE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dataScience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "24e4cd118faed2a7f4ff0294d1a1b4521466fc1fb850bf8e754b6eda5f0ef937"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
